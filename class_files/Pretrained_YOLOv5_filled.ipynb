{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "\n",
        "\n",
        "This is the **a YOLOv5 ðŸš€ notebook** by **Ultralytics**, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
        "For more information please visit https://github.com/ultralytics/yolov5 and https://ultralytics.com. Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2758a8bc-cc69-4027-ce3f-a5de0cc6db39"
      },
      "source": [
        "# Cloning Repo\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12676, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 12676 (delta 20), reused 21 (delta 9), pack-reused 12633\u001b[K\n",
            "Receiving objects: 100% (12676/12676), 12.87 MiB | 28.41 MiB/s, done.\n",
            "Resolving deltas: 100% (8729/8729), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc5DeQ4BWTU0",
        "outputId": "b829d9aa-f31c-4f6e-d5d5-7529887789e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34myolov5\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to yolov5\n",
        "%cd yolov5\n",
        "\n",
        "# Install libraries \n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbYx3FUuQUcn",
        "outputId": "662fe972-d7a2-4e9c-835c-a6ef8c336572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v6.2-159-gd669a74 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 37.6/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# Detect\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
        "\n",
        "```shell\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image \n",
        "                          vid.mp4  # video\n",
        "                          path/  # directory\n",
        "                          'path/*.jpg'  # glob\n",
        "                          'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters \n",
        "- yolov5s  > Size of model , the bigger the size the more accurate but the slower the model is  (https://github.com/ultralytics/yolov5/releases)\n",
        "- weights > pretrained neural network that we will use \n",
        "-  img  > size of image for training 640 is the default and best as this is used in the training \n",
        "- conf > the confidence of the model where the model will show the bounding box \n",
        "\n",
        "COCO stands for Common Objects in Context is from a paper released in 2014"
      ],
      "metadata": {
        "id": "5pirkUo6WDZc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f25b60bb-1476-4c12-aa56-8f186c9578cd"
      },
      "source": [
        "# run code detect.py \n",
        "\n",
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v6.2-159-gd669a74 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 313MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "image 1/2 /content/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 16.2ms\n",
            "image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 16.7ms\n",
            "Speed: 0.5ms pre-process, 16.5ms inference, 18.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try using a picture of a hammer "
      ],
      "metadata": {
        "id": "6R3MFk_ni6gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ../Claw-hammer.jpg"
      ],
      "metadata": {
        "id": "ShAC0-oRlSQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88cab2c2-bfca-4dca-bac8-f081e9b2e231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=../Claw-hammer.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v6.2-159-gd669a74 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "image 1/1 /content/Claw-hammer.jpg: 320x640 (no detections), 12.4ms\n",
            "Speed: 0.5ms pre-process, 12.4ms inference, 0.7ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# COCO Dataset Classes\n",
        "https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/ "
      ],
      "metadata": {
        "id": "F5_7oqEXlajO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try it yourself . \n",
        "- Get a random picture online and test it using the YOLOv5 algorithm \n",
        "- Save a cropped image of the image detected\n",
        "- Test the detection using different weight N, S,XL \n",
        "  - Is the confidence better ? \n",
        "  - Is it faster or slower ?"
      ],
      "metadata": {
        "id": "4jFrXAaEk6kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov5n.pt --img 640 --conf 0.25 --source ../Snowboarding.jpg"
      ],
      "metadata": {
        "id": "TgubDzmbUB8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b250022-c7f7-4435-9e63-f134865a92eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5n.pt'], source=../Snowboarding.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v6.2-159-gd669a74 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n.pt to yolov5n.pt...\n",
            "100% 3.87M/3.87M [00:00<00:00, 75.6MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
            "image 1/1 /content/Snowboarding.jpg: 384x640 1 person, 11.9ms\n",
            "Speed: 0.4ms pre-process, 11.9ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov5x.pt --img 640 --conf 0.25 --source ../Snowboarding.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOjP3EutMbCH",
        "outputId": "4a595c49-1920-4b65-8195-cdfa34fe8ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5x.pt'], source=../Snowboarding.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v6.2-159-gd669a74 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5x.pt to yolov5x.pt...\n",
            "100% 166M/166M [00:01<00:00, 127MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients\n",
            "image 1/1 /content/Snowboarding.jpg: 384x640 1 person, 54.7ms\n",
            "Speed: 0.5ms pre-process, 54.7ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n"
      ],
      "metadata": {
        "id": "UjNdris8Fe0E"
      }
    }
  ]
}