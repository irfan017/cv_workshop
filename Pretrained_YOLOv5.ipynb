{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "\n",
        "\n",
        "This is the **a YOLOv5 ðŸš€ notebook** by **Ultralytics**, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
        "For more information please visit https://github.com/ultralytics/yolov5 and https://ultralytics.com. Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab62b691-f6f3-4545-db8f-008bba2b6a13"
      },
      "source": [
        "# Cloning Repo\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12367, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 12367 (delta 33), reused 34 (delta 16), pack-reused 12292\u001b[K\n",
            "Receiving objects: 100% (12367/12367), 12.76 MiB | 21.25 MiB/s, done.\n",
            "Resolving deltas: 100% (8504/8504), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc5DeQ4BWTU0",
        "outputId": "2e285a90-881c-4dd0-def8-1415db809fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34myolov5\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to yolov5\n",
        "%cd yolov5\n",
        "\n",
        "# Install libraries \n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbYx3FUuQUcn",
        "outputId": "dfce1beb-ad53-459f-d48a-5175578bb72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v6.2-123-g5e1a955 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 37.4/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# Detect\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
        "\n",
        "```shell\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image \n",
        "                          vid.mp4  # video\n",
        "                          path/  # directory\n",
        "                          'path/*.jpg'  # glob\n",
        "                          'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters \n",
        "- yolov5s  > Size of model , the bigger the size the more accurate but the slower the model is  (https://github.com/ultralytics/yolov5/releases)\n",
        "- weights > pretrained neural network that we will use \n",
        "-  img  > size of image for training 640 is the default and best as this is used in the training \n",
        "- conf > the confidence of the model where the model will show the bounding box \n",
        "\n",
        "COCO stands for Common Objects in Context is from a paper released in 2014"
      ],
      "metadata": {
        "id": "5pirkUo6WDZc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67946eaf-afc2-47fe-b157-942655abb099"
      },
      "source": [
        "# run code detect.py \n",
        "\n",
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v6.2-123-g5e1a955 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 171MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "image 1/2 /content/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 16.2ms\n",
            "image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 13.3ms\n",
            "Speed: 0.5ms pre-process, 14.8ms inference, 18.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try using a picture of a hammer "
      ],
      "metadata": {
        "id": "6R3MFk_ni6gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source # insert picture here"
      ],
      "metadata": {
        "id": "ShAC0-oRlSQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# COCO Dataset Classes\n",
        "https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/ "
      ],
      "metadata": {
        "id": "F5_7oqEXlajO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try it yourself . \n",
        "- Get a random picture online and test it using the YOLOv5 algorithm \n",
        "- Save a cropped image of the image detected\n",
        "- Test the detection using different weight N, S,XL \n",
        "  - Is the confidence better ? \n",
        "  - Is it faster or slower ?"
      ],
      "metadata": {
        "id": "4jFrXAaEk6kC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TgubDzmbUB8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n"
      ],
      "metadata": {
        "id": "UjNdris8Fe0E"
      }
    }
  ]
}